<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to Neural Networks and Their History</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #ffffff;
            font-size: 150%;
        }
        section {
            margin-bottom: 20px;
            padding: 20px;
            background-color: #ffffff;
            display: none;
            opacity: 0;
            transition: opacity 0.5s ease-in;
        }
        h1, h2, h3, h4 {
            color: #333;
            margin-top: 20px;
        }
        p, li {
            line-height: 1.6;
            color: #444;
            margin-bottom: 20px;
        }
        ul {
            padding-left: 20px;
        }
        .image-placeholder, .interactive-placeholder, .continue-button, .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
            text-align: left;
        }
        .image-placeholder img, .interactive-placeholder img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
        }
        .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
            padding: 20px;
            border-radius: 8px;
            margin-top: 20px;
        }
        .vocab-section {
            background-color: #f0f8ff;
        }
        .vocab-section h3 {
            color: #1e90ff;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .vocab-section h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
        .vocab-term {
            font-weight: bold;
            color: #1e90ff;
        }
        .why-it-matters {
            background-color: #ffe6f0;
        }
        .why-it-matters h3 {
            color: #d81b60;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .stop-and-think {
            background-color: #e6e6ff;
        }
        .stop-and-think h3 {
            color: #4b0082;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .continue-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #007bff;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
        }
        .reveal-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #4b0082;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
        }
        .test-your-knowledge {
            background-color: #e6ffe6;
        }
        .test-your-knowledge h3 {
            color: #28a745;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .test-your-knowledge h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
        .test-your-knowledge p {
            margin-bottom: 15px;
        }
        .check-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #28a745;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
            border: none;
            font-size: 1em;
        }
        .faq-section {
            background-color: #fffbea;
        }
        .faq-section h3 {
            color: #ffcc00;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .faq-section h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <section id="section1">
<div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="A futuristic cityscape with self-driving cars, robots, and other AI-powered technologies, symbolizing the impact of neural networks.">
        </div>
        <h1>Welcome to Neural Networks!</h1>
        <p>Get ready to dive into the fascinating world of Neural Networks. These powerful models are at the heart of many modern AI applications, from self-driving cars to virtual assistants. They've revolutionized machine learning, enabling us to tackle problems that were once considered impossible. But where did it all begin?</p>
        <div class="continue-button" onclick="showNextSection(2)">Continue</div>
    </section>

    <section id="section2">
        <h2>The History of Neural Networks in a nutshell</h2>
        <p>Let's go on a journey through time to explore the key milestones in the history of neural networks. Our story starts way back in 1943, when the first artificial neuron, called the <strong>"Threshold Logic Unit (TLU)"</strong>, was proposed. This was a very basic mathematical model, but it laid the foundation for everything that followed.</p>
        <div class="continue-button" onclick="showNextSection(3)">Continue</div>
    </section>

    <section id="section3">
<div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="A comic stylised version of a Frank Rosenblatt, saying "I think I found something big!"">
        </div>
        <p>Fast forward to 1957. <strong>Frank Rosenblatt</strong>, a brilliant scientist, developed the <strong>perceptron</strong>. This was the simplest form of an artificial neural network, capable of learning simple patterns. Think of it as the first baby step towards the complex networks we have today.</p>
        <div class="vocab-section">
            <h3>Build Your Vocab</h3>
            <h4 class="vocab-term">Perceptron</h4>
            <p>The perceptron is the simplest form of an artificial neural network. It's a single-layer network that can learn linearly separable patterns.</p>
        </div>
        <div class="continue-button" onclick="showNextSection(4)">Continue</div>
    </section>

    <section id="section4">
        <p>In 1965, another breakthrough occurred: the first working <strong>feedforward multilayer</strong> network was successfully applied for <strong>supervised learning</strong>. This meant that networks could now have multiple layers of interconnected neurons, allowing them to learn more complex relationships in the data. It was like going from a single-story house to a multi-story building!</p>
<div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="...">
        </div>
        <div class="continue-button" onclick="showNextSection(5)">Continue</div>
    </section>

    <section id="section5">
        <p>The 1970s brought us the <strong>backpropagation</strong> algorithm, a crucial development that enabled us to train these multi-layered networks efficiently. Before backpropagation, training complex networks was a major challenge. Think of backpropagation as the ingenious architect that made skyscrapers possible.</p>
        <div class="vocab-section">
            <h3>Build Your Vocab</h3>
            <h4 class="vocab-term">Backpropagation</h4>
            <p>An algorithm for efficiently training artificial neural networks, especially those with multiple layers. It works by calculating the error at the output and propagating it back through the network to update the weights.</p>
        </div>
        <div class="continue-button" onclick="showNextSection(6)">Continue</div>
    </section>

    <section id="section6">
<div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="Roboter with eyes, saying I can see!">
        </div>
        <p>In 1979, researchers developed the precursors of <strong>Convolutional Neural Networks (CNNs)</strong>. These specialized networks are particularly good at processing images, and they've revolutionized computer vision. Imagine them as the specialized tools for image analysis.</p>
        <div class="continue-button" onclick="showNextSection(7)">Continue</div>
    </section>

    <section id="section7">
        <p>Then, in 1982, <strong>Recurrent Neural Networks (RNNs)</strong> were developed. These networks have a "memory" that allows them to process sequences of data, like text or audio. They are like the storytellers of the neural network world, capable of understanding context and time dependencies.</p>
        <div class="continue-button" onclick="showNextSection(8)">Continue</div>
    </section>

    <section id="section8">
        <p>1986 saw the first successful training of a <strong>multi-layered neural network</strong> using <strong>backpropagation</strong>, a pivotal moment that confirmed the power of this algorithm.</p>
        <div class="continue-button" onclick="showNextSection(9)">Continue</div>
    </section>

    <section id="section9">
        <p>In 1997, <strong>Long Short-Term Memory (LSTM)</strong> networks were introduced. These are a special type of RNN that can remember information over longer periods, making them even better at handling sequential data. They are like the upgraded version of RNNs with enhanced memory capabilities.</p>
        <div class="continue-button" onclick="showNextSection(10)">Continue</div>
    </section>

    <section id="section10">
        <p>The years between 2006 and 2012 marked the beginning of the <strong>deep learning</strong> era. Deep learning involves training neural networks with many layers, enabling them to learn incredibly complex patterns and representations. This was like the renaissance of neural networks, a period of rapid advancement and discovery!</p>
        <div class="continue-button" onclick="showNextSection(11)">Continue</div>
    </section>

    <section id="section11">
        <p>2012 was a landmark year. A deep learning network called <strong>AlexNet</strong> won the ImageNet competition by a huge margin. This demonstrated the power of deep learning for image recognition and set the stage for many future breakthroughs. It was like the moment when deep learning truly took center stage.</p>
        <div class="continue-button" onclick="showNextSection(12)">Continue</div>
    </section>

    <section id="section12">
<div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="A frustrated Lee Sedol sitting together with an Robot at an Go board.">
        </div>
        <p>And in 2016, <strong>AlphaGo</strong>, a deep learning system from Google, defeated the world champion in the game of Go. This was a historic achievement, as Go was considered a much more challenging game for AI than chess. AlphaGo showed that deep learning could master complex strategic thinking.</p>
        <div class="continue-button" onclick="showNextSection(13)">Continue</div>
    </section>

    <section id="section13">
        <h2>The Fuel of Deep Learning: Data</h2>
        <p>Now, you might be wondering, what's behind this recent explosion of deep learning? One crucial factor is <strong>data</strong>. Deep learning models are incredibly data-hungry. They thrive on massive datasets, using them to learn intricate patterns and make accurate predictions.</p>
        <div class="continue-button" onclick="showNextSection(14)">Continue</div>
    </section>

    <section id="section14">
        <p>Andrew Ng, a leading figure in AI, once said...</p>
<div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="Andrew Ng saying "The analogy to deep learning is that the rocket engine is the deep learning models and the fuel is the huge amounts of data we can feed to these algorithms."">
        </div>
<p>This perfectly captures the relationship between deep learning and data. More data often translates to better performance.</p>
        <div class="continue-button" onclick="showNextSection(15)">Continue</div>
    </section>

    <section id="section15">
        <p>Let's look at a graph that illustrates this:</p>
        <div class="visualaid-placeholder">
            <img src="/placeholder.svg?height=400&width=600" alt="Deep Learning vs. Classical Learning: Performance Scaling,
1. Axes:
- The x-axis represents the "Amount of Training Data."
- The y-axis represents "Performance."
2. Performance Curve:
- Classical Learning (Red Line): Initially, performance improves with the increasing amount of training data, but it reaches a plateau where additional training data does not significantly improve performance.
- Deep Learning (Blue Line): Performance starts similarly to classical learning with smaller amounts of data but continues to improve significantly as more training data is added, surpassing classical learning's performance.">
        </div>
        <p>Deep learning models, fueled by large datasets, outperform classical methods as the amount of training data increases.</p>
        <div class="continue-button" onclick="showNextSection(16)">Continue</div>
    </section>

    <section id="section16">
        <p>As you can see, classical machine learning methods tend to plateau in performance as the dataset grows. But deep learning models continue to improve, getting better and better with more data. This is one of the key reasons why deep learning has become so dominant in recent years.</p>
        <div class="continue-button" onclick="showNextSection(17)">Continue</div>
    </section>

    <section id="section17">
        <p>It's like comparing a small car with a limited fuel tank to a powerful rocket with a massive fuel supply. The rocket can go much farther and achieve much greater heights because it has more fuel to burn.</p>
        <div class="why-it-matters">
            <h3>Why It Matters</h3>
            <p>The ability of deep learning to leverage large datasets is a game-changer. It means that as we collect more and more data in various domains, we can build increasingly powerful and accurate AI models.</p>
        </div>
        <div class="continue-button" onclick="showNextSection(18)">Continue</div>
    </section>

    <section id="section18">
        <div class="stop-and-think">
            <h3>Stop and Think</h3>
            <h4>Can you think of some areas where large datasets are being generated that could be used to train deep learning models?</h4>
            <button class="reveal-button" onclick="revealAnswer('stop-and-think-1')">Reveal</button>
            <p id="stop-and-think-1" style="display: none;">Some examples include: social media (text, images, videos), online shopping (customer behavior, product information), medical records (patient data, medical images), and scientific research (experimental data, simulations).</p>
        </div>
        <div class="continue-button" onclick="showNextSection(19)">Continue</div>
    </section>

    <section id="section19">
        <div class="faq-section">
            <h3>Frequently Asked Questions</h3>
            <h4>Why is deep learning so popular now if neural networks have been around for so long?</h4>
            <p>Several factors have contributed to the rise of deep learning: the availability of massive datasets, the development of powerful hardware like GPUs, and algorithmic advancements like backpropagation and new network architectures.</p>
            <h4>What's the difference between artificial intelligence, machine learning, and deep learning?</h4>
            <p>Artificial intelligence (AI) is the broad concept of creating machines that can perform tasks that typically require human intelligence. Machine learning (ML) is a subset of AI where machines learn from data without being explicitly programmed. Deep learning is a subset of ML that uses deep neural networks with multiple layers to learn complex patterns.</p>
        </div>
        <div class="continue-button" onclick="showNextSection(20)">Continue</div>
    </section>

    

    <section id="section20">
        <h2>Review and Reflect</h2>
        <p>In this introductory lesson, we've taken a journey through the fascinating history of neural networks, from the early days of the perceptron to the modern era of deep learning. We've seen how key innovations and the availability of large datasets have fueled the rise of these powerful models. We also discussed the importance of data for deep learning and how it outperforms classical machine learning methods when fueled with large datasets. In the next lesson, we'll explore the impact of deep learning with the ImageNet example.</p>
        
    </section>

    <script>
        // Show the first section initially
        document.getElementById("section1").style.display = "block";
        document.getElementById("section1").style.opacity = "1";

        function showNextSection(nextSectionId) {
            const currentButton = event.target;
            const nextSection = document.getElementById("section" + nextSectionId);
            
            currentButton.style.display = "none";
            
            nextSection.style.display = "block";
            setTimeout(() => {
                nextSection.style.opacity = "1";
            }, 10);

            setTimeout(() => {
                nextSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }, 500);
        }

        function revealAnswer(id) {
            const revealText = document.getElementById(id);
            const revealButton = event.target;
            
            revealText.style.display = "block";
            revealButton.style.display = "none";
        }

        function checkAnswers() {
            const correctAnswers = [true, true, true, false];
            let userScore = 0;
            
            for (let i = 1; i <= 4; i++) {
                const checkbox = document.getElementById("option" + i);
                if (checkbox.checked === correctAnswers[i-1]) {
                    userScore++;
                }
            }
            
            const resultElement = document.getElementById("result");
            resultElement.textContent = `You got ${userScore} out of 4 correct!`;
            
            // Display explanations
            const explanations = [
                "Correct, the perceptron was developed in 1957 by Frank Rosenblatt and was the simplest form of an artificial neural network.",
                "Correct, backpropagation is a crucial algorithm for efficiently training neural networks with multiple layers.",
                "Absolutely right, deep learning models thrive on large datasets and their performance generally improves as the amount of training data increases.",
                "CNNs are primarily used for processing images. Recurrent Neural Networks (RNNs) are better suited for text data."
            ];
            
            for (let i = 1; i <= 4; i++) {
                const checkbox = document.getElementById("option" + i);
                const label = document.querySelector(`label[for="option${i}"]`);
                const explanation = document.createElement("p");
                explanation.textContent = explanations[i-1];
                explanation.style.color = checkbox.checked === correctAnswers[i-1] ? "green" : "red";
                label.parentNode.insertBefore(explanation, label.nextSibling);
            }
        }
    </script>
</body>
</html>
